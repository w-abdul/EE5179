{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrUVXuMSkDQQ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9EtAGtyTQJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_AuUCJJkRiD"
      },
      "source": [
        "## Utilising GPU using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERUEzqqakS3e",
        "outputId": "e4809953-cabc-4fc6-dfed-19040552ca69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# cpu-gpu\n",
        "a = torch.randn((3, 4))\n",
        "print(a.device)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "a = a.to(device)\n",
        "print(a.device)\n",
        "\n",
        "# a more generic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n474i7A4kjm3",
        "outputId": "04977b3f-bda9-4650-db48-cd484781f104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 19 09:07:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    25W /  70W |    612MiB / 15109MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxjZWEfIkn7X"
      },
      "source": [
        "## Dataset and Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f1bafea83f2542d6a1d21015dcbaf077",
            "5f235fef0d6a4386a5bf62a9ed24e97c",
            "afd223ae3a31496ca9cfcc7e058a607e",
            "49e78fbb80664713a07a2e4b50cbc35c",
            "fa8339b6d3f44d9a806e949d7d245590",
            "0e145fed2afc4d46aad50e4bbb52359c",
            "730df6fcad8543569778d4b021692b55",
            "7d7f180db3c94529a7403b689b7b5868",
            "ea673433615647c9b23e24bc86a6a247",
            "a814c68bcc674554a03bb3d417163250",
            "a6a5149a7c684455820b0a19cf29798a"
          ]
        },
        "id": "Afh2_n-PTc_U",
        "outputId": "a8d0259a-f222-4127-fd53-232537996df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1bafea83f2542d6a1d21015dcbaf077"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=True, transform=train_transform, download=True)\n",
        "test_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=False, transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwrVIg6BUUKI",
        "outputId": "eb0c6e81-1f17-4352-8663-7daf80e8703f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train samples: 50000\n",
            "# of test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train samples: {len(train_dset)}\")\n",
        "print(f\"# of test samples: {len(test_dset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_RniHmyUgsz"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dset, batch_size=100, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GoIkiN8VJXx",
        "outputId": "c6755d42-9493-4f60-8aca-ce7d21eb97d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train batches: 500\n",
            "# of test batches: 100\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train batches: {len(train_loader)}\")\n",
        "print(f\"# of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uokKboX4VO02",
        "outputId": "00f8a2a7-b629-42dd-fec4-fa638867868e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample i/o sizes\n",
            "input size: torch.Size([100, 3, 32, 32])\n",
            "output size: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(\"sample i/o sizes\")\n",
        "data = next(iter(train_loader))\n",
        "img, target = data\n",
        "print(f\"input size: {img.shape}\")\n",
        "print(f\"output size: {target.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJjyNdKkr1t"
      },
      "source": [
        "## LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usjem5RSVdso"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    # TODO: missing input feature size\n",
        "    self.fc1   = nn.Linear(16*5*5, 120)\n",
        "    self.fc2   = nn.Linear(120, 84)\n",
        "    # TODO: missing output feature size\n",
        "    self.fc3   = nn.Linear(84, 10)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "  # TODO: add maxpool operation of given kernel size\n",
        "  # https://pytorch.org/docs/stable/nn.functional.html\n",
        "  def pool(self, x, kernel_size=2):\n",
        "    out = F.max_pool2d(x, kernel_size=2)\n",
        "    return out\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.conv1(x))\n",
        "    out = self.pool(out)\n",
        "    out = self.activ(self.conv2(out))\n",
        "    out = self.pool(out)\n",
        "\n",
        "    # TODO: flatten\n",
        "    out = out.view(out.size(0),-1) \n",
        "    out = self.activ(self.fc1(out))\n",
        "    out = self.activ(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJAne7Wfkuvr"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDgBFjcgXxqC"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"vgg11\": [64, \"pool\", 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg13\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg16\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, \"pool\", 512, 512, 512, \"pool\", 512, 512, 512, \"pool\"],\n",
        "      \"vgg19\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, 256, \"pool\", 512, 512, 512, 512, \"pool\", 512, 512, 512, 512, \"pool\"],\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(VGG, self).__init__()\n",
        "    # TODO: missing input dimension\n",
        "    in_dim = 3\n",
        "    layers = []\n",
        "    for layer in self.CONFIGS[cfg]:\n",
        "        if layer == \"pool\":\n",
        "            # TODO: add maxpool module of given kernel size, stride (here 2 each)\n",
        "            # https://pytorch.org/docs/stable/nn.html\n",
        "            maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            layers.append(maxpool)\n",
        "        else:\n",
        "            # TODO: add sequential module consisting of convolution (kernel size = 3, padding = 1), batchnorm, relu\n",
        "            # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential\n",
        "            block = nn.Sequential(nn.Conv2d(in_dim,layer,kernel_size = 3, padding = 1),nn.BatchNorm2d(layer),nn.ReLU())\n",
        "            layers.append(block)\n",
        "            in_dim = layer\n",
        "    # TODO: add average pool to collapse spatial dimensions\n",
        "    avgpool = nn.AvgPool2d(Kernel_size=1, stride=1)\n",
        "    layers.append(avgpool)\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "    # TODO: missing output features\n",
        "    self.fc = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    # TODO: flatten\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRtGz0Z_kwJr"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwEtA8o0bRnz"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (stride != 1 or in_dim != self.expansion*dim):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, self.expansion*dim, kernel_size=1, stride=stride),nn.BatchNorm2d(self.expansion*dim))\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    # TODO: missing residual connection\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.conv3 = nn.Conv2d(dim, self.expansion * dim, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (stride != 1 or in_dim != self.expansion*dim):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, self.expansion*dim, kernel_size=1, stride=stride),nn.BatchNorm2d(self.expansion*dim))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.activ(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    # TODO: missing residual connection\n",
        "    out =  out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"resnet18\": (BasicBlock, [2, 2, 2, 2]),\n",
        "      \"resnet34\": (BasicBlock, [3, 4, 6, 3]),\n",
        "      \"resnet50\": (Bottleneck, [3, 4, 6, 3]),\n",
        "      \"resnet101\": (Bottleneck, [3, 4, 23, 3]),\n",
        "      \"resnet152\": (Bottleneck, [3, 8, 36, 3]),\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(ResNet, self).__init__()\n",
        "    block, num_blocks = self.CONFIGS[cfg]\n",
        "    self.in_dim = 64\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.activ = nn.ReLU()\n",
        "    # TODO: missing output features\n",
        "    self.linear = nn.Linear(512*block.expansion, 10)\n",
        "\n",
        "  def _make_layer(self, block, dim, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)    \n",
        "    layers = []\n",
        "    for stride in strides: \n",
        "        # TODO: create layers within block\n",
        "        layer = block(self.in_dim, dim, stride)\n",
        "        layers.append(layer)\n",
        "        # TODO: update in_dim based on block output size\n",
        "        self.in_dim = dim * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    # TODO: average pool and flatten\n",
        "    out = F.avg_pool2d(out,4)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4ywUDe3k0ZQ"
      },
      "source": [
        "## Utility functions (can ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUXIGxAvfdBc"
      },
      "outputs": [],
      "source": [
        "def pbar(p=0, msg=\"\", bar_len=20):\n",
        "    sys.stdout.write(\"\\033[K\")\n",
        "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
        "    block = int(round(bar_len * p))\n",
        "    text = \"Progress: [{}] {}% {}\".format(\n",
        "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
        "        round(p * 100, 2),\n",
        "        msg,\n",
        "    )\n",
        "    print(text, end=\"\\r\")\n",
        "    if p == 1:\n",
        "        print()\n",
        "\n",
        "\n",
        "class AvgMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def add(self, batch_metrics):\n",
        "        if self.metrics == {}:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key] = [value]\n",
        "        else:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key].append(value)\n",
        "\n",
        "    def get(self):\n",
        "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "\n",
        "    def msg(self):\n",
        "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM4qJwaDlBwD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdwembsSja6-"
      },
      "outputs": [],
      "source": [
        "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
        "  model.to(device)\n",
        "  best_acc = 0\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(train_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: missing backward, parameter update\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "\n",
        "      metric_meter.add({\"train loss\": loss.item()})\n",
        "      pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "\n",
        "    model.eval()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(test_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: compute accuracy\n",
        "      classes = torch.argmax(out, dim=1)\n",
        "      acc_t = torch.mean((classes == target).float())\n",
        "      acc=acc_t.cpu().detach().numpy()\n",
        "\n",
        "      metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
        "      pbar(indx / len(test_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "    \n",
        "    test_metrics = metric_meter.get()\n",
        "    if test_metrics[\"test acc\"] > best_acc:\n",
        "      print(\n",
        "          \"\\x1b[33m\"\n",
        "          + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)}\"\n",
        "          + \"\\033[0m\"\n",
        "      )\n",
        "      best_acc = test_metrics['test acc']\n",
        "      torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
        "    lr_sched.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QSyZus3lD7f"
      },
      "source": [
        "## Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wy8hIQfiGqS"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_name=\"lenet\", model_cfg=None, epochs=200):\n",
        "  if model_name == \"lenet\":\n",
        "    model = LeNet()\n",
        "  elif model_name == \"vgg\":\n",
        "    model = VGG(model_cfg)\n",
        "  elif model_name == \"resnet\":\n",
        "    model = ResNet(model_cfg)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "  optim = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
        "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  metric_meter = AvgMeter()\n",
        "  out_dir = f\"{model_name}_{model_cfg}\"\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  train(model, optim, lr_sched, epochs=epochs, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgYPvSM4jUEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693fc797-8516-428d-8858-c8de2cf51c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.00656 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.92018 [test acc] 0.29340 \n",
            "\u001b[33mtest acc improved from 0 to 0.29339998960494995\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89082 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.76347 [test acc] 0.34950 \n",
            "\u001b[33mtest acc improved from 0.29339998960494995 to 0.34950000047683716\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86197 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83136 [test acc] 0.31370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84665 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.92990 [test acc] 0.29330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86395 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.80284 [test acc] 0.32590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.82464 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82656 [test acc] 0.32970 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.79459 \n",
            "\n",
            "\u001b[33mtest acc improved from 0.34950000047683716 to 0.36039999127388\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.81022 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.78776 [test acc] 0.34600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.78988 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.69828 [test acc] 0.37580 \n",
            "\u001b[33mtest acc improved from 0.36039999127388 to 0.3758000135421753\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.75975 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.67963 [test acc] 0.36460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.75988 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.68496 [test acc] 0.40290 \n",
            "\u001b[33mtest acc improved from 0.3758000135421753 to 0.40290001034736633\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.75567 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.67780 [test acc] 0.37980 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.75927 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.63737 [test acc] 0.41850 \n",
            "\u001b[33mtest acc improved from 0.40290001034736633 to 0.41850000619888306\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.74160 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.72128 [test acc] 0.39220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.73636 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.63735 [test acc] 0.41250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.73343 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.67550 [test acc] 0.38470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.73554 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.64851 [test acc] 0.42200 \n",
            "\u001b[33mtest acc improved from 0.41850000619888306 to 0.421999990940094\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.70986 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.69442 [test acc] 0.39480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.72244 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.70304 [test acc] 0.40380 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.72407 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.57505 [test acc] 0.43570 \n",
            "\u001b[33mtest acc improved from 0.421999990940094 to 0.435699999332428\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.68091 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.67733 [test acc] 0.41090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.70956 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.64045 [test acc] 0.41720 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.67449 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.65545 [test acc] 0.42430 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.70027 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.65902 [test acc] 0.41010 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.68811 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.62283 [test acc] 0.40190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.65292 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.68595 [test acc] 0.39480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.68402 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.63813 [test acc] 0.41850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.66581 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.63262 [test acc] 0.41840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.67385 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.66392 [test acc] 0.41640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.67507 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.58685 [test acc] 0.43120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.66761 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.60854 [test acc] 0.42820 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.68517 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.55950 [test acc] 0.44300 \n",
            "\u001b[33mtest acc improved from 0.435699999332428 to 0.4429999887943268\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.65014 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.63344 [test acc] 0.38450 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.65557 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.55146 [test acc] 0.46290 \n",
            "\u001b[33mtest acc improved from 0.4429999887943268 to 0.4629000127315521\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.64408 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.53296 [test acc] 0.46230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.63723 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.52284 [test acc] 0.45830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.62792 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.52091 [test acc] 0.47480 \n",
            "\u001b[33mtest acc improved from 0.4629000127315521 to 0.4747999906539917\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.62777 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.60308 [test acc] 0.42390 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.63659 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.51418 [test acc] 0.47140 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.63787 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.51139 [test acc] 0.47350 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.64800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.57851 [test acc] 0.43840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.63282 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.56665 [test acc] 0.45150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.61803 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.58313 [test acc] 0.42210 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.59923 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.50435 [test acc] 0.46160 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.61480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.48793 [test acc] 0.47850 \n",
            "\u001b[33mtest acc improved from 0.4747999906539917 to 0.47850000858306885\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.62882 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.54332 [test acc] 0.44810 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.63760 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.56003 [test acc] 0.44490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.60693 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.54978 [test acc] 0.44710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.61026 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.47612 [test acc] 0.49070 \n",
            "\u001b[33mtest acc improved from 0.47850000858306885 to 0.49070000648498535\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.61551 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.49502 [test acc] 0.48090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.59556 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.46404 [test acc] 0.49060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.60905 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.54596 [test acc] 0.46130 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.60349 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.52293 [test acc] 0.45420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.59318 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.50027 [test acc] 0.47530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.60144 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.57309 [test acc] 0.46690 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.57512 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.62572 [test acc] 0.43530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.59673 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.53883 [test acc] 0.46510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.60465 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.56388 [test acc] 0.43750 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.56421 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.49257 [test acc] 0.48420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.58426 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.48749 [test acc] 0.47370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.54784 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.62196 [test acc] 0.41980 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.53856 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.43352 [test acc] 0.50350 \n",
            "\u001b[33mtest acc improved from 0.49070000648498535 to 0.5034999847412109\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.55407 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.46123 [test acc] 0.50070 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.55673 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.55146 [test acc] 0.45650 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.54700 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.42106 [test acc] 0.51100 \n",
            "\u001b[33mtest acc improved from 0.5034999847412109 to 0.5109999775886536\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.55380 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.43729 [test acc] 0.48460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.53256 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.46806 [test acc] 0.48750 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.52308 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.36155 [test acc] 0.52930 \n",
            "\u001b[33mtest acc improved from 0.5109999775886536 to 0.5292999744415283\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.53566 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.53320 [test acc] 0.46960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.54225 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.41494 [test acc] 0.50310 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.53625 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.42587 [test acc] 0.50380 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.49464 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.41123 [test acc] 0.51090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.52079 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.40338 [test acc] 0.51270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.49806 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.50552 [test acc] 0.48850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.49833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.40774 [test acc] 0.50570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.48852 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.40232 [test acc] 0.51130 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.48693 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.42391 [test acc] 0.51060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.47693 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.35483 [test acc] 0.53720 \n",
            "\u001b[33mtest acc improved from 0.5292999744415283 to 0.5371999740600586\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.46619 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.42834 [test acc] 0.50060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.44838 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.34234 [test acc] 0.54000 \n",
            "\u001b[33mtest acc improved from 0.5371999740600586 to 0.5400000214576721\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.46062 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.29987 [test acc] 0.55920 \n",
            "\u001b[33mtest acc improved from 0.5400000214576721 to 0.5591999888420105\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.47069 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.33241 [test acc] 0.54170 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.45110 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.31591 [test acc] 0.55220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.45696 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.41552 [test acc] 0.50870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.45339 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.29731 [test acc] 0.55300 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.41121 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.36437 [test acc] 0.53510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.41345 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.29220 [test acc] 0.55420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.41505 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.34847 [test acc] 0.52580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.40954 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.45882 [test acc] 0.48860 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.41186 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.32881 [test acc] 0.54800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.39959 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.20247 [test acc] 0.58330 \n",
            "\u001b[33mtest acc improved from 0.5591999888420105 to 0.583299994468689\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.39765 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.31927 [test acc] 0.54960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.37148 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.24470 [test acc] 0.56240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.36785 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.31057 [test acc] 0.55500 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.36524 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.27024 [test acc] 0.56580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.36235 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.26292 [test acc] 0.56530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.34557 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.32907 [test acc] 0.54260 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.35176 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.21719 [test acc] 0.58610 \n",
            "\u001b[33mtest acc improved from 0.583299994468689 to 0.5860999822616577\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.33363 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.25371 [test acc] 0.57950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.33544 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.21320 [test acc] 0.58730 \n",
            "\u001b[33mtest acc improved from 0.5860999822616577 to 0.5873000025749207\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.33337 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.27555 [test acc] 0.56120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.31734 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.22794 [test acc] 0.58250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.30983 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.28890 [test acc] 0.56610 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.29154 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.14106 [test acc] 0.61010 \n",
            "\u001b[33mtest acc improved from 0.5873000025749207 to 0.6100999712944031\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.30008 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.21802 [test acc] 0.57810 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.29639 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.20501 [test acc] 0.59080 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.27405 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.18303 [test acc] 0.58910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.26227 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.16005 [test acc] 0.60220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.26074 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.20288 [test acc] 0.58320 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.25952 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.16258 [test acc] 0.59460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.26417 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.16426 [test acc] 0.61030 \n",
            "\u001b[33mtest acc improved from 0.6100999712944031 to 0.6103000044822693\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.25810 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.11335 [test acc] 0.61680 \n",
            "\u001b[33mtest acc improved from 0.6103000044822693 to 0.6168000102043152\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.23756 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.12986 [test acc] 0.60980 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.23144 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.15234 [test acc] 0.61470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.23622 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.15694 [test acc] 0.61760 \n",
            "\u001b[33mtest acc improved from 0.6168000102043152 to 0.6176000237464905\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.21272 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.16338 [test acc] 0.61020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.20078 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.12323 [test acc] 0.62090 \n",
            "\u001b[33mtest acc improved from 0.6176000237464905 to 0.6208999752998352\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.19428 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.08345 [test acc] 0.62530 \n",
            "\u001b[33mtest acc improved from 0.6208999752998352 to 0.6252999901771545\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.18168 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.18561 [test acc] 0.60040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.17540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.15676 [test acc] 0.60390 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.16734 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.11157 [test acc] 0.61830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.16237 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.07518 [test acc] 0.63390 \n",
            "\u001b[33mtest acc improved from 0.6252999901771545 to 0.633899986743927\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.15730 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.02782 [test acc] 0.64760 \n",
            "\u001b[33mtest acc improved from 0.633899986743927 to 0.647599995136261\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.13436 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.09836 [test acc] 0.62230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.14498 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.07885 [test acc] 0.62880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.13126 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.02979 [test acc] 0.64970 \n",
            "\u001b[33mtest acc improved from 0.647599995136261 to 0.6496999859809875\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.12388 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.05974 [test acc] 0.63330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.11429 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.04211 [test acc] 0.64470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.10803 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.99386 [test acc] 0.65260 \n",
            "\u001b[33mtest acc improved from 0.6496999859809875 to 0.6525999903678894\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.10595 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.99490 [test acc] 0.65780 \n",
            "\u001b[33mtest acc improved from 0.6525999903678894 to 0.657800018787384\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.09826 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.03151 [test acc] 0.64070 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.09118 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.99989 [test acc] 0.65710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.07682 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.06343 [test acc] 0.64000 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.07835 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.99866 [test acc] 0.65950 \n",
            "\u001b[33mtest acc improved from 0.657800018787384 to 0.659500002861023\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.06617 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.98254 [test acc] 0.66010 \n",
            "\u001b[33mtest acc improved from 0.659500002861023 to 0.660099983215332\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.06027 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.98671 [test acc] 0.66040 \n",
            "\u001b[33mtest acc improved from 0.660099983215332 to 0.6603999733924866\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.05833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.01912 [test acc] 0.64900 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.04374 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.98700 [test acc] 0.66180 \n",
            "\u001b[33mtest acc improved from 0.6603999733924866 to 0.6618000268936157\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.02845 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.94125 [test acc] 0.68190 \n",
            "\u001b[33mtest acc improved from 0.6618000268936157 to 0.6819000244140625\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.02286 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.95101 [test acc] 0.67570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.02578 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.97487 [test acc] 0.65820 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.01986 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.94376 [test acc] 0.67480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.00993 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.94039 [test acc] 0.67150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.00827 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92569 [test acc] 0.67670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.99494 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.93559 [test acc] 0.68180 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.99314 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92356 [test acc] 0.68340 \n",
            "\u001b[33mtest acc improved from 0.6819000244140625 to 0.6833999752998352\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.99050 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.91952 [test acc] 0.68630 \n",
            "\u001b[33mtest acc improved from 0.6833999752998352 to 0.6862999796867371\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.98314 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.89519 [test acc] 0.69340 \n",
            "\u001b[33mtest acc improved from 0.6862999796867371 to 0.6934000253677368\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.96423 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.91471 [test acc] 0.68480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.96298 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.88403 [test acc] 0.69420 \n",
            "\u001b[33mtest acc improved from 0.6934000253677368 to 0.6941999793052673\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.95615 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.88759 [test acc] 0.69290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.94755 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92442 [test acc] 0.67920 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.94471 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.85962 [test acc] 0.70450 \n",
            "\u001b[33mtest acc improved from 0.6941999793052673 to 0.7045000195503235\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.93802 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.86412 [test acc] 0.70040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.93684 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.86648 [test acc] 0.70670 \n",
            "\u001b[33mtest acc improved from 0.7045000195503235 to 0.7067000269889832\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.92805 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92787 [test acc] 0.68260 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.91654 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.83663 [test acc] 0.70960 \n",
            "\u001b[33mtest acc improved from 0.7067000269889832 to 0.7095999717712402\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.90830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.88759 [test acc] 0.69190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.90250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.84864 [test acc] 0.70530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.89682 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.82937 [test acc] 0.71240 \n",
            "\u001b[33mtest acc improved from 0.7095999717712402 to 0.7124000191688538\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.89448 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.85499 [test acc] 0.70390 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.88954 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.83475 [test acc] 0.71040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.88311 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.81904 [test acc] 0.71290 \n",
            "\u001b[33mtest acc improved from 0.7124000191688538 to 0.7128999829292297\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.88029 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.82736 [test acc] 0.71560 \n",
            "\u001b[33mtest acc improved from 0.7128999829292297 to 0.7156000137329102\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.86119 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.83984 [test acc] 0.70710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.86677 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.82880 [test acc] 0.71590 \n",
            "\u001b[33mtest acc improved from 0.7156000137329102 to 0.7159000039100647\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.85834 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.84072 [test acc] 0.70600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.85004 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.84258 [test acc] 0.70690 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.84307 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79615 [test acc] 0.72280 \n",
            "\u001b[33mtest acc improved from 0.7159000039100647 to 0.7228000164031982\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.84037 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79348 [test acc] 0.72310 \n",
            "\u001b[33mtest acc improved from 0.7228000164031982 to 0.7231000065803528\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.83824 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.80122 [test acc] 0.72060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.82777 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.78805 [test acc] 0.72480 \n",
            "\u001b[33mtest acc improved from 0.7231000065803528 to 0.7247999906539917\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.82483 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.78119 [test acc] 0.72960 \n",
            "\u001b[33mtest acc improved from 0.7247999906539917 to 0.7296000123023987\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.81838 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.77145 [test acc] 0.73170 \n",
            "\u001b[33mtest acc improved from 0.7296000123023987 to 0.7317000031471252\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.81197 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79211 [test acc] 0.72510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.80465 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.76492 [test acc] 0.73380 \n",
            "\u001b[33mtest acc improved from 0.7317000031471252 to 0.7337999939918518\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.80239 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.78130 [test acc] 0.72800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.79389 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.75941 [test acc] 0.73410 \n",
            "\u001b[33mtest acc improved from 0.7337999939918518 to 0.7340999841690063\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.79326 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.75766 [test acc] 0.73520 \n",
            "\u001b[33mtest acc improved from 0.7340999841690063 to 0.7351999878883362\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.78966 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79080 [test acc] 0.72610 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.78636 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74992 [test acc] 0.74120 \n",
            "\u001b[33mtest acc improved from 0.7351999878883362 to 0.7411999702453613\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.77997 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.76275 [test acc] 0.73100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.76905 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74974 [test acc] 0.73470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.76859 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.75247 [test acc] 0.73970 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.76662 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74834 [test acc] 0.74030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.76131 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74014 [test acc] 0.74070 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.75545 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74064 [test acc] 0.73990 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.75509 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73743 [test acc] 0.74140 \n",
            "\u001b[33mtest acc improved from 0.7411999702453613 to 0.7414000034332275\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.75084 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73985 [test acc] 0.74130 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.74958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73142 [test acc] 0.74580 \n",
            "\u001b[33mtest acc improved from 0.7414000034332275 to 0.7458000183105469\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.75171 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73394 [test acc] 0.74370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.74725 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72948 [test acc] 0.74540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73978 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72654 [test acc] 0.74570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.74046 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72923 [test acc] 0.74580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73522 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72731 [test acc] 0.74580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73753 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72709 [test acc] 0.74600 \n",
            "\u001b[33mtest acc improved from 0.7458000183105469 to 0.7459999918937683\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73436 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72738 [test acc] 0.74570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73395 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72656 [test acc] 0.74550 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73473 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72569 [test acc] 0.74500 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.73460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72580 [test acc] 0.74610 \n",
            "\u001b[33mtest acc improved from 0.7459999918937683 to 0.7461000084877014\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "run_experiment(model_name=\"lenet\")\n",
        "#run_experiment(model_name=\"vgg\",model_cfg=\"vgg16\")\n",
        "#run_experiment(model_name=\"resnet\",model_cfg=\"resnet18\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HBcgGTHlQqx"
      },
      "source": [
        "## Questions\n",
        "- Train and report test set metrics on three model types - LeNet, VGG, ResNet. \n",
        "- Which model performs the best and why?\n",
        "- Which model performs the worst and why?\n",
        "- BONUS (extra marks): Modify the LeNet model's convolution layers and compare performance against number of layers (depth), number of nodes per layer (width). (Require atleast 3 data points each for width and depth). Feel free to reduce the number of epochs to obtain results quickly. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1bafea83f2542d6a1d21015dcbaf077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f235fef0d6a4386a5bf62a9ed24e97c",
              "IPY_MODEL_afd223ae3a31496ca9cfcc7e058a607e",
              "IPY_MODEL_49e78fbb80664713a07a2e4b50cbc35c"
            ],
            "layout": "IPY_MODEL_fa8339b6d3f44d9a806e949d7d245590"
          }
        },
        "5f235fef0d6a4386a5bf62a9ed24e97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e145fed2afc4d46aad50e4bbb52359c",
            "placeholder": "",
            "style": "IPY_MODEL_730df6fcad8543569778d4b021692b55",
            "value": "100%"
          }
        },
        "afd223ae3a31496ca9cfcc7e058a607e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7f180db3c94529a7403b689b7b5868",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea673433615647c9b23e24bc86a6a247",
            "value": 170498071
          }
        },
        "49e78fbb80664713a07a2e4b50cbc35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a814c68bcc674554a03bb3d417163250",
            "placeholder": "",
            "style": "IPY_MODEL_a6a5149a7c684455820b0a19cf29798a",
            "value": " 170498071/170498071 [00:06&lt;00:00, 24828585.12it/s]"
          }
        },
        "fa8339b6d3f44d9a806e949d7d245590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e145fed2afc4d46aad50e4bbb52359c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730df6fcad8543569778d4b021692b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7f180db3c94529a7403b689b7b5868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea673433615647c9b23e24bc86a6a247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a814c68bcc674554a03bb3d417163250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a5149a7c684455820b0a19cf29798a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}