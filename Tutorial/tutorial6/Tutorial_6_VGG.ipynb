{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4825d218d6a34f2db4643677d02db73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_047d952b576b4d2597b421eb4d5d4b77",
              "IPY_MODEL_a6b43e641a564ec89530b74e8ded6ed5",
              "IPY_MODEL_d901dca51bc4469fa42f237b7fa41ff9"
            ],
            "layout": "IPY_MODEL_91920862428346d8a1e3ed736056f052"
          }
        },
        "047d952b576b4d2597b421eb4d5d4b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96bd850fb54a4a51b4510b04bbfa677f",
            "placeholder": "​",
            "style": "IPY_MODEL_a3dee62fd32c473b8ad022f2e544722d",
            "value": "100%"
          }
        },
        "a6b43e641a564ec89530b74e8ded6ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d1d722afb94789af46d72afad27a97",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06207595be0a4356b9c09583f8e9350d",
            "value": 170498071
          }
        },
        "d901dca51bc4469fa42f237b7fa41ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d106a06247f648b697851b15d22325d2",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3b709d67ab435fb9b395e525d8eda9",
            "value": " 170498071/170498071 [00:03&lt;00:00, 63308899.05it/s]"
          }
        },
        "91920862428346d8a1e3ed736056f052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bd850fb54a4a51b4510b04bbfa677f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3dee62fd32c473b8ad022f2e544722d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d1d722afb94789af46d72afad27a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06207595be0a4356b9c09583f8e9350d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d106a06247f648b697851b15d22325d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3b709d67ab435fb9b395e525d8eda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A9EtAGtyTQJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ERUEzqqakS3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a8c7b8-7002-4261-ad45-4cfc9aee4920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# cpu-gpu\n",
        "a = torch.randn((3, 4))\n",
        "print(a.device)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "a = a.to(device)\n",
        "print(a.device)\n",
        "\n",
        "# a more generic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr-clnRudugS",
        "outputId": "5fcab0fb-2cb0-4df5-f386-42a560b4654c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 20 06:01:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W /  70W |    612MiB / 15109MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Afh2_n-PTc_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "4825d218d6a34f2db4643677d02db73a",
            "047d952b576b4d2597b421eb4d5d4b77",
            "a6b43e641a564ec89530b74e8ded6ed5",
            "d901dca51bc4469fa42f237b7fa41ff9",
            "91920862428346d8a1e3ed736056f052",
            "96bd850fb54a4a51b4510b04bbfa677f",
            "a3dee62fd32c473b8ad022f2e544722d",
            "c4d1d722afb94789af46d72afad27a97",
            "06207595be0a4356b9c09583f8e9350d",
            "d106a06247f648b697851b15d22325d2",
            "3c3b709d67ab435fb9b395e525d8eda9"
          ]
        },
        "outputId": "ccb7e70a-0de6-4d26-cda5-810df900fb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4825d218d6a34f2db4643677d02db73a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=True, transform=train_transform, download=True)\n",
        "test_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=False, transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rwrVIg6BUUKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6411da-9f98-437e-989a-d91761de1213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train samples: 50000\n",
            "# of test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train samples: {len(train_dset)}\")\n",
        "print(f\"# of test samples: {len(test_dset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R_RniHmyUgsz"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dset, batch_size=100, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4GoIkiN8VJXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2fe90c-8214-4a60-cc17-73421e86e83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train batches: 500\n",
            "# of test batches: 100\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train batches: {len(train_loader)}\")\n",
        "print(f\"# of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uokKboX4VO02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c072da18-8d0c-48a7-962d-37187b4021b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample i/o sizes\n",
            "input size: torch.Size([100, 3, 32, 32])\n",
            "output size: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(\"sample i/o sizes\")\n",
        "data = next(iter(train_loader))\n",
        "img, target = data\n",
        "print(f\"input size: {img.shape}\")\n",
        "print(f\"output size: {target.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG"
      ],
      "metadata": {
        "id": "36GdgTWLeHii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rDgBFjcgXxqC"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"vgg11\": [64, \"pool\", 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg13\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg16\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, \"pool\", 512, 512, 512, \"pool\", 512, 512, 512, \"pool\"],\n",
        "      \"vgg19\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, 256, \"pool\", 512, 512, 512, 512, \"pool\", 512, 512, 512, 512, \"pool\"],\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(VGG, self).__init__()\n",
        "    # TODO: missing input dimension\n",
        "    in_dim = 3\n",
        "    layers = []\n",
        "    for layer in self.CONFIGS[cfg]:\n",
        "        if layer == \"pool\":\n",
        "            # TODO: add maxpool module of given kernel size, stride (here 2 each)\n",
        "            # https://pytorch.org/docs/stable/nn.html\n",
        "            maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            layers.append(maxpool)\n",
        "        else:\n",
        "            # TODO: add sequential module consisting of convolution (kernel size = 3, padding = 1), batchnorm, relu\n",
        "            # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential\n",
        "            block = nn.Sequential(nn.Conv2d(in_dim,layer,kernel_size = 3, padding = 1),nn.BatchNorm2d(layer),nn.ReLU())\n",
        "            layers.append(block)\n",
        "            in_dim = layer\n",
        "    # TODO: add average pool to collapse spatial dimensions\n",
        "    avgpool = nn.AvgPool2d(kernel_size=1, stride=1)\n",
        "    layers.append(avgpool)\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "    # TODO: missing output features\n",
        "    self.fc = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    # TODO: flatten\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Function"
      ],
      "metadata": {
        "id": "ZDSin4EyeydP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iUXIGxAvfdBc"
      },
      "outputs": [],
      "source": [
        "def pbar(p=0, msg=\"\", bar_len=20):\n",
        "    sys.stdout.write(\"\\033[K\")\n",
        "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
        "    block = int(round(bar_len * p))\n",
        "    text = \"Progress: [{}] {}% {}\".format(\n",
        "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
        "        round(p * 100, 2),\n",
        "        msg,\n",
        "    )\n",
        "    print(text, end=\"\\r\")\n",
        "    if p == 1:\n",
        "        print()\n",
        "\n",
        "\n",
        "class AvgMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def add(self, batch_metrics):\n",
        "        if self.metrics == {}:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key] = [value]\n",
        "        else:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key].append(value)\n",
        "\n",
        "    def get(self):\n",
        "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "\n",
        "    def msg(self):\n",
        "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "p6C8NKWbeh3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XdwembsSja6-"
      },
      "outputs": [],
      "source": [
        "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
        "  model.to(device)\n",
        "  best_acc = 0\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(train_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: missing backward, parameter update\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "\n",
        "      metric_meter.add({\"train loss\": loss.item()})\n",
        "      pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "\n",
        "    model.eval()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(test_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: compute accuracy\n",
        "      classes = torch.argmax(out, dim=1)\n",
        "      acc_t = torch.mean((classes == target).float())\n",
        "      acc=acc_t.cpu().detach().numpy()\n",
        "\n",
        "      metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
        "      pbar(indx / len(test_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "    \n",
        "    test_metrics = metric_meter.get()\n",
        "    if test_metrics[\"test acc\"] > best_acc:\n",
        "      print(\n",
        "          \"\\x1b[33m\"\n",
        "          + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)}\"\n",
        "          + \"\\033[0m\"\n",
        "      )\n",
        "      best_acc = test_metrics['test acc']\n",
        "      torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
        "    lr_sched.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Experiment"
      ],
      "metadata": {
        "id": "-BZjibhcecCK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1Wy8hIQfiGqS"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_name=\"lenet\", model_cfg=None, epochs=200):\n",
        "  if model_name == \"lenet\":\n",
        "    model = LeNet()\n",
        "  elif model_name == \"vgg\":\n",
        "    model = VGG(model_cfg)\n",
        "  elif model_name == \"resnet\":\n",
        "    model = ResNet(model_cfg)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "  optim = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
        "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  metric_meter = AvgMeter()\n",
        "  out_dir = f\"{model_name}_{model_cfg}\"\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  train(model, optim, lr_sched, epochs=epochs, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jgYPvSM4jUEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e186d5-932e-46ea-bea6-6d2f6533de98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.43741 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.27571 [test acc] 0.12240 \n",
            "\u001b[33mtest acc improved from 0 to 0.12240000069141388\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.15777 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01523 [test acc] 0.20210 \n",
            "\u001b[33mtest acc improved from 0.12240000069141388 to 0.2020999938249588\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.75383 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.57512 [test acc] 0.38300 \n",
            "\u001b[33mtest acc improved from 0.2020999938249588 to 0.382999986410141\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.41090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.47428 [test acc] 0.45730 \n",
            "\u001b[33mtest acc improved from 0.382999986410141 to 0.45730000734329224\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.10383 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.28717 [test acc] 0.55860 \n",
            "\u001b[33mtest acc improved from 0.45730000734329224 to 0.5586000084877014\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.94596 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.04255 [test acc] 0.65100 \n",
            "\u001b[33mtest acc improved from 0.5586000084877014 to 0.6510000228881836\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.85159 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.87722 [test acc] 0.71680 \n",
            "\u001b[33mtest acc improved from 0.6510000228881836 to 0.7167999744415283\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.78066 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.95240 [test acc] 0.67930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.71895 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.82185 [test acc] 0.73160 \n",
            "\u001b[33mtest acc improved from 0.7167999744415283 to 0.7315999865531921\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.68325 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.78355 [test acc] 0.74870 \n",
            "\u001b[33mtest acc improved from 0.7315999865531921 to 0.7487000226974487\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.66148 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.19123 [test acc] 0.64860 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.63586 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.94673 [test acc] 0.70830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.61579 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.96056 [test acc] 0.70010 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.59644 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73166 [test acc] 0.75550 \n",
            "\u001b[33mtest acc improved from 0.7487000226974487 to 0.7555000185966492\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.58947 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92268 [test acc] 0.70460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.57526 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.68503 [test acc] 0.77980 \n",
            "\u001b[33mtest acc improved from 0.7555000185966492 to 0.7797999978065491\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.56541 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.84118 [test acc] 0.74680 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.56005 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92086 [test acc] 0.70860 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.54796 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.81298 [test acc] 0.73920 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.54104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.74659 [test acc] 0.76510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.53150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.78766 [test acc] 0.74910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.53685 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.65000 [test acc] 0.79040 \n",
            "\u001b[33mtest acc improved from 0.7797999978065491 to 0.7904000282287598\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.51958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.59966 [test acc] 0.79830 \n",
            "\u001b[33mtest acc improved from 0.7904000282287598 to 0.79830002784729\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.51418 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.15367 [test acc] 0.65090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.50881 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.93850 [test acc] 0.73340 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.50370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60012 [test acc] 0.80650 \n",
            "\u001b[33mtest acc improved from 0.79830002784729 to 0.8065000176429749\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.50371 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.54434 [test acc] 0.81510 \n",
            "\u001b[33mtest acc improved from 0.8065000176429749 to 0.8151000142097473\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.49179 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55716 [test acc] 0.81620 \n",
            "\u001b[33mtest acc improved from 0.8151000142097473 to 0.8162000179290771\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.48591 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.61838 [test acc] 0.79520 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.48434 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.54507 [test acc] 0.82230 \n",
            "\u001b[33mtest acc improved from 0.8162000179290771 to 0.8223000168800354\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.48351 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.57774 [test acc] 0.80630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.48166 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79354 [test acc] 0.75290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.47267 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.81501 [test acc] 0.74450 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.47451 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60215 [test acc] 0.80010 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46418 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58963 [test acc] 0.81160 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46823 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.63595 [test acc] 0.80060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46704 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.63663 [test acc] 0.79090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72127 [test acc] 0.77610 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45308 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51323 [test acc] 0.83430 \n",
            "\u001b[33mtest acc improved from 0.8223000168800354 to 0.8342999815940857\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46112 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.63917 [test acc] 0.79840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45013 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52299 [test acc] 0.83750 \n",
            "\u001b[33mtest acc improved from 0.8342999815940857 to 0.8374999761581421\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45285 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52978 [test acc] 0.82530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45367 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58607 [test acc] 0.81080 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43717 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58295 [test acc] 0.81200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43863 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.80173 [test acc] 0.75200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43783 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.71489 [test acc] 0.77230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.44448 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.92406 [test acc] 0.72640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43438 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73909 [test acc] 0.77120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43397 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.53792 [test acc] 0.83220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42938 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60883 [test acc] 0.80390 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42217 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72535 [test acc] 0.76730 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41809 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52877 [test acc] 0.82930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42424 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.65518 [test acc] 0.80490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41445 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.81874 [test acc] 0.75000 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41156 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.68939 [test acc] 0.77800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41568 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60818 [test acc] 0.80350 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41291 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79581 [test acc] 0.75020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40575 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55240 [test acc] 0.82140 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49006 [test acc] 0.83660 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40483 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.62341 [test acc] 0.80250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40272 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.56075 [test acc] 0.81710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.39524 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.59206 [test acc] 0.80190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.39403 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55673 [test acc] 0.82060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.39477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49823 [test acc] 0.83320 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38644 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.59119 [test acc] 0.80830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38518 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.93848 [test acc] 0.73880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.39243 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49965 [test acc] 0.83520 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38346 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.67748 [test acc] 0.78690 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37987 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50749 [test acc] 0.83240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37818 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.54292 [test acc] 0.82850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37082 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52308 [test acc] 0.83230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37077 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51265 [test acc] 0.83270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60411 [test acc] 0.80870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36747 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50991 [test acc] 0.83940 \n",
            "\u001b[33mtest acc improved from 0.8374999761581421 to 0.8393999934196472\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36423 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49480 [test acc] 0.84170 \n",
            "\u001b[33mtest acc improved from 0.8393999934196472 to 0.84170001745224\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36138 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.62587 [test acc] 0.80660 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35896 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.44495 [test acc] 0.85240 \n",
            "\u001b[33mtest acc improved from 0.84170001745224 to 0.852400004863739\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35399 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50227 [test acc] 0.83900 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35261 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.48066 [test acc] 0.84760 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34791 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43968 [test acc] 0.85760 \n",
            "\u001b[33mtest acc improved from 0.852400004863739 to 0.8575999736785889\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34415 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.57201 [test acc] 0.82020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35233 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60165 [test acc] 0.79580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.44514 [test acc] 0.85800 \n",
            "\u001b[33mtest acc improved from 0.8575999736785889 to 0.8579999804496765\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33671 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.53959 [test acc] 0.82330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33752 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.48102 [test acc] 0.84380 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34067 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55462 [test acc] 0.82930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33025 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.53355 [test acc] 0.83300 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32636 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45474 [test acc] 0.85140 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31997 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51966 [test acc] 0.83090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32611 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55225 [test acc] 0.81710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31730 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50284 [test acc] 0.83780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31194 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46335 [test acc] 0.84360 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30891 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.65309 [test acc] 0.80210 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50178 [test acc] 0.83620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30712 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39078 [test acc] 0.87360 \n",
            "\u001b[33mtest acc improved from 0.8579999804496765 to 0.8736000061035156\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30161 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49244 [test acc] 0.83870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.29413 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55777 [test acc] 0.82910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.29082 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55259 [test acc] 0.83170 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.29042 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43274 [test acc] 0.86090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28985 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46950 [test acc] 0.84940 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28404 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.47032 [test acc] 0.84830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28569 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46872 [test acc] 0.85030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27805 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51016 [test acc] 0.83590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27429 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.44994 [test acc] 0.85410 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27054 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52196 [test acc] 0.83680 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26123 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41816 [test acc] 0.86910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26980 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.62100 [test acc] 0.80490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26042 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39290 [test acc] 0.86830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25375 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.42569 [test acc] 0.86540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25187 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45054 [test acc] 0.85600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25445 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39948 [test acc] 0.87550 \n",
            "\u001b[33mtest acc improved from 0.8736000061035156 to 0.8755000233650208\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25076 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43146 [test acc] 0.86040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24128 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45400 [test acc] 0.86040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24168 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.59834 [test acc] 0.82780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24276 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40902 [test acc] 0.86400 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23293 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46016 [test acc] 0.85770 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23366 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50444 [test acc] 0.84290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.22219 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38991 [test acc] 0.87450 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.22483 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43264 [test acc] 0.86740 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.21787 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38165 [test acc] 0.88190 \n",
            "\u001b[33mtest acc improved from 0.8755000233650208 to 0.8819000124931335\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.21791 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46715 [test acc] 0.85910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20379 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.48176 [test acc] 0.84960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20554 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38515 [test acc] 0.87870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20743 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39597 [test acc] 0.87420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.19934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41861 [test acc] 0.87470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.19777 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43148 [test acc] 0.86600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18707 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38446 [test acc] 0.88220 \n",
            "\u001b[33mtest acc improved from 0.8819000124931335 to 0.8822000026702881\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18832 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40244 [test acc] 0.87330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18546 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.37185 [test acc] 0.88230 \n",
            "\u001b[33mtest acc improved from 0.8822000026702881 to 0.8823000192642212\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.17773 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35290 [test acc] 0.88670 \n",
            "\u001b[33mtest acc improved from 0.8823000192642212 to 0.8866999745368958\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.17434 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40696 [test acc] 0.87150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.17026 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34326 [test acc] 0.89260 \n",
            "\u001b[33mtest acc improved from 0.8866999745368958 to 0.8925999999046326\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.16572 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41350 [test acc] 0.87780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.16253 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41391 [test acc] 0.87470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.15592 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34621 [test acc] 0.89370 \n",
            "\u001b[33mtest acc improved from 0.8925999999046326 to 0.8937000036239624\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.14803 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31537 [test acc] 0.90700 \n",
            "\u001b[33mtest acc improved from 0.8937000036239624 to 0.9070000052452087\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.15477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41742 [test acc] 0.87180 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.14739 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34888 [test acc] 0.89520 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13945 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33618 [test acc] 0.89710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13246 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38035 [test acc] 0.88560 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13828 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32354 [test acc] 0.90100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.12804 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33079 [test acc] 0.89930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.12918 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38422 [test acc] 0.88910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.11940 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34529 [test acc] 0.89870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.11710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35632 [test acc] 0.89360 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.11354 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33216 [test acc] 0.90150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.37462 [test acc] 0.89190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10391 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.36327 [test acc] 0.89510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10101 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38514 [test acc] 0.88840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.09392 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30992 [test acc] 0.90550 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08863 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34771 [test acc] 0.90120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.09013 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34580 [test acc] 0.90460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08672 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31442 [test acc] 0.91140 \n",
            "\u001b[33mtest acc improved from 0.9070000052452087 to 0.9114000201225281\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.07575 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35543 [test acc] 0.89930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.07620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35518 [test acc] 0.90170 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.07298 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33046 [test acc] 0.90630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.07267 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30680 [test acc] 0.91490 \n",
            "\u001b[33mtest acc improved from 0.9114000201225281 to 0.914900004863739\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.06675 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32233 [test acc] 0.91110 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.06133 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30942 [test acc] 0.91710 \n",
            "\u001b[33mtest acc improved from 0.914900004863739 to 0.9171000123023987\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05519 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30657 [test acc] 0.91540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05695 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33571 [test acc] 0.90740 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05045 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32072 [test acc] 0.91640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05022 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.36119 [test acc] 0.90580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.04391 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33419 [test acc] 0.91310 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.04147 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28143 [test acc] 0.92450 \n",
            "\u001b[33mtest acc improved from 0.9171000123023987 to 0.9244999885559082\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03813 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27076 [test acc] 0.92640 \n",
            "\u001b[33mtest acc improved from 0.9244999885559082 to 0.9264000058174133\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03340 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27723 [test acc] 0.92790 \n",
            "\u001b[33mtest acc improved from 0.9264000058174133 to 0.9279000163078308\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03125 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27825 [test acc] 0.92640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02722 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31739 [test acc] 0.92020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02358 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30152 [test acc] 0.92420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02300 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28631 [test acc] 0.93130 \n",
            "\u001b[33mtest acc improved from 0.9279000163078308 to 0.9312999844551086\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01901 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31231 [test acc] 0.92500 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01674 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31635 [test acc] 0.92620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01709 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29380 [test acc] 0.92920 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01239 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29747 [test acc] 0.93180 \n",
            "\u001b[33mtest acc improved from 0.9312999844551086 to 0.9318000078201294\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01273 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30107 [test acc] 0.92940 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00984 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28656 [test acc] 0.93350 \n",
            "\u001b[33mtest acc improved from 0.9318000078201294 to 0.9334999918937683\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00824 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29035 [test acc] 0.93410 \n",
            "\u001b[33mtest acc improved from 0.9334999918937683 to 0.9340999722480774\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00896 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28022 [test acc] 0.93270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00669 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29008 [test acc] 0.93060 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00587 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28816 [test acc] 0.93370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00432 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29229 [test acc] 0.93450 \n",
            "\u001b[33mtest acc improved from 0.9340999722480774 to 0.934499979019165\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00441 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29248 [test acc] 0.93200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00423 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29553 [test acc] 0.93200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00343 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28942 [test acc] 0.93400 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00331 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28932 [test acc] 0.93500 \n",
            "\u001b[33mtest acc improved from 0.934499979019165 to 0.9350000023841858\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00253 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28580 [test acc] 0.93540 \n",
            "\u001b[33mtest acc improved from 0.9350000023841858 to 0.9354000091552734\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00226 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28209 [test acc] 0.93550 \n",
            "\u001b[33mtest acc improved from 0.9354000091552734 to 0.9355000257492065\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00187 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28653 [test acc] 0.93580 \n",
            "\u001b[33mtest acc improved from 0.9355000257492065 to 0.9358000159263611\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00245 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27999 [test acc] 0.93550 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00218 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28027 [test acc] 0.93670 \n",
            "\u001b[33mtest acc improved from 0.9358000159263611 to 0.9366999864578247\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00162 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28137 [test acc] 0.93580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00215 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27802 [test acc] 0.93630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00181 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28170 [test acc] 0.93630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00185 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27801 [test acc] 0.93560 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00155 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27866 [test acc] 0.93610 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00162 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27962 [test acc] 0.93710 \n",
            "\u001b[33mtest acc improved from 0.9366999864578247 to 0.9370999932289124\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00147 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27911 [test acc] 0.93740 \n",
            "\u001b[33mtest acc improved from 0.9370999932289124 to 0.9373999834060669\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00176 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27848 [test acc] 0.93670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00208 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27758 [test acc] 0.93670 \n"
          ]
        }
      ],
      "source": [
        "#run_experiment(model_name=\"lenet\")\n",
        "run_experiment(model_name=\"vgg\",model_cfg=\"vgg16\")\n",
        "#run_experiment(model_name=\"resnet\",model_cfg=\"resnet18\")"
      ]
    }
  ]
}