{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrUVXuMSkDQQ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A9EtAGtyTQJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_AuUCJJkRiD"
      },
      "source": [
        "## Utilising GPU using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERUEzqqakS3e",
        "outputId": "6d7aa340-9224-4a0b-f064-880c2bbff042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# cpu-gpu\n",
        "a = torch.randn((3, 4))\n",
        "print(a.device)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "a = a.to(device)\n",
        "print(a.device)\n",
        "\n",
        "# a more generic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n474i7A4kjm3",
        "outputId": "58ab8f60-53fe-422a-f71a-26cc9d69aac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 19 11:44:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    27W /  70W |    612MiB / 15109MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxjZWEfIkn7X"
      },
      "source": [
        "## Dataset and Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "3afd43ab438647739cac7cb7fb0af123",
            "48feeba233b141c5898c9ff7f088ec0a",
            "720ff9f4c25045c59627e505028c9184",
            "833bdbf80ab3407abf01045099ff4000",
            "1b4d4ea3e3c548988f47cd0ae8aadc6f",
            "ad00e33feaec427f8962d5e2f5a8fde8",
            "f423142f0ab342b3a20c2fa7e7b73b41",
            "28f5604493e04528babe637b63274acf",
            "c1de76a75f9646f79099b00681b8577a",
            "2edc56c583504cfc9416692e821bf2d4",
            "8e27e56fcc214224beb88235128c3570"
          ]
        },
        "id": "Afh2_n-PTc_U",
        "outputId": "51455f9d-3ba3-4784-d383-c1c9e4e038e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3afd43ab438647739cac7cb7fb0af123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=True, transform=train_transform, download=True)\n",
        "test_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=False, transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwrVIg6BUUKI",
        "outputId": "7f38d686-8923-47be-c0b9-573c3ee92210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train samples: 50000\n",
            "# of test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train samples: {len(train_dset)}\")\n",
        "print(f\"# of test samples: {len(test_dset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R_RniHmyUgsz"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dset, batch_size=100, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GoIkiN8VJXx",
        "outputId": "ebae24ad-d87b-48b9-de3c-d51b223d81a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train batches: 500\n",
            "# of test batches: 100\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train batches: {len(train_loader)}\")\n",
        "print(f\"# of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uokKboX4VO02",
        "outputId": "aae989b8-4198-45db-d727-b0a009677a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample i/o sizes\n",
            "input size: torch.Size([100, 3, 32, 32])\n",
            "output size: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(\"sample i/o sizes\")\n",
        "data = next(iter(train_loader))\n",
        "img, target = data\n",
        "print(f\"input size: {img.shape}\")\n",
        "print(f\"output size: {target.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJjyNdKkr1t"
      },
      "source": [
        "## LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Usjem5RSVdso"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    # TODO: missing input feature size\n",
        "    self.fc1   = nn.Linear(16*5*5, 120)\n",
        "    self.fc2   = nn.Linear(120, 84)\n",
        "    # TODO: missing output feature size\n",
        "    self.fc3   = nn.Linear(84, 10)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "  # TODO: add maxpool operation of given kernel size\n",
        "  # https://pytorch.org/docs/stable/nn.functional.html\n",
        "  def pool(self, x, kernel_size=2):\n",
        "    out = F.max_pool2d(x, kernel_size=2)\n",
        "    return out\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.conv1(x))\n",
        "    out = self.pool(out)\n",
        "    out = self.activ(self.conv2(out))\n",
        "    out = self.pool(out)\n",
        "\n",
        "    # TODO: flatten\n",
        "    out = out.view(out.size(0),-1) \n",
        "    out = self.activ(self.fc1(out))\n",
        "    out = self.activ(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJAne7Wfkuvr"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rDgBFjcgXxqC"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"vgg11\": [64, \"pool\", 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg13\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg16\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, \"pool\", 512, 512, 512, \"pool\", 512, 512, 512, \"pool\"],\n",
        "      \"vgg19\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, 256, \"pool\", 512, 512, 512, 512, \"pool\", 512, 512, 512, 512, \"pool\"],\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(VGG, self).__init__()\n",
        "    # TODO: missing input dimension\n",
        "    in_dim = 3\n",
        "    layers = []\n",
        "    for layer in self.CONFIGS[cfg]:\n",
        "        if layer == \"pool\":\n",
        "            # TODO: add maxpool module of given kernel size, stride (here 2 each)\n",
        "            # https://pytorch.org/docs/stable/nn.html\n",
        "            maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            layers.append(maxpool)\n",
        "        else:\n",
        "            # TODO: add sequential module consisting of convolution (kernel size = 3, padding = 1), batchnorm, relu\n",
        "            # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential\n",
        "            block = nn.Sequential(nn.Conv2d(in_dim,layer,kernel_size = 3, padding = 1),nn.BatchNorm2d(layer),nn.ReLU())\n",
        "            layers.append(block)\n",
        "            in_dim = layer\n",
        "    # TODO: add average pool to collapse spatial dimensions\n",
        "    avgpool = nn.AvgPool2d(Kernel_size=1, stride=1)\n",
        "    layers.append(avgpool)\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "    # TODO: missing output features\n",
        "    self.fc = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    # TODO: flatten\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRtGz0Z_kwJr"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HwEtA8o0bRnz"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (stride != 1 or in_dim != self.expansion*dim):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, self.expansion*dim, kernel_size=1, stride=stride),nn.BatchNorm2d(self.expansion*dim))\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    # TODO: missing residual connection\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.conv3 = nn.Conv2d(dim, self.expansion * dim, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (stride != 1 or in_dim != self.expansion*dim):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, self.expansion*dim, kernel_size=1, stride=stride),nn.BatchNorm2d(self.expansion*dim))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.activ(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    # TODO: missing residual connection\n",
        "    out =  out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"resnet18\": (BasicBlock, [2, 2, 2, 2]),\n",
        "      \"resnet34\": (BasicBlock, [3, 4, 6, 3]),\n",
        "      \"resnet50\": (Bottleneck, [3, 4, 6, 3]),\n",
        "      \"resnet101\": (Bottleneck, [3, 4, 23, 3]),\n",
        "      \"resnet152\": (Bottleneck, [3, 8, 36, 3]),\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(ResNet, self).__init__()\n",
        "    block, num_blocks = self.CONFIGS[cfg]\n",
        "    self.in_dim = 64\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.activ = nn.ReLU()\n",
        "    # TODO: missing output features\n",
        "    self.linear = nn.Linear(512*block.expansion, 10)\n",
        "\n",
        "  def _make_layer(self, block, dim, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)    \n",
        "    layers = []\n",
        "    for stride in strides: \n",
        "        # TODO: create layers within block\n",
        "        layer = block(self.in_dim, dim, stride)\n",
        "        layers.append(layer)\n",
        "        # TODO: update in_dim based on block output size\n",
        "        self.in_dim = dim * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    # TODO: average pool and flatten\n",
        "    out = F.avg_pool2d(out,4)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4ywUDe3k0ZQ"
      },
      "source": [
        "## Utility functions (can ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iUXIGxAvfdBc"
      },
      "outputs": [],
      "source": [
        "def pbar(p=0, msg=\"\", bar_len=20):\n",
        "    sys.stdout.write(\"\\033[K\")\n",
        "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
        "    block = int(round(bar_len * p))\n",
        "    text = \"Progress: [{}] {}% {}\".format(\n",
        "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
        "        round(p * 100, 2),\n",
        "        msg,\n",
        "    )\n",
        "    print(text, end=\"\\r\")\n",
        "    if p == 1:\n",
        "        print()\n",
        "\n",
        "\n",
        "class AvgMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def add(self, batch_metrics):\n",
        "        if self.metrics == {}:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key] = [value]\n",
        "        else:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key].append(value)\n",
        "\n",
        "    def get(self):\n",
        "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "\n",
        "    def msg(self):\n",
        "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM4qJwaDlBwD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XdwembsSja6-"
      },
      "outputs": [],
      "source": [
        "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
        "  model.to(device)\n",
        "  best_acc = 0\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(train_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: missing backward, parameter update\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "\n",
        "      metric_meter.add({\"train loss\": loss.item()})\n",
        "      pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "\n",
        "    model.eval()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(test_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: compute accuracy\n",
        "      classes = torch.argmax(out, dim=1)\n",
        "      acc_t = torch.mean((classes == target).float())\n",
        "      acc=acc_t.cpu().detach().numpy()\n",
        "\n",
        "      metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
        "      pbar(indx / len(test_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "    \n",
        "    test_metrics = metric_meter.get()\n",
        "    if test_metrics[\"test acc\"] > best_acc:\n",
        "      print(\n",
        "          \"\\x1b[33m\"\n",
        "          + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)}\"\n",
        "          + \"\\033[0m\"\n",
        "      )\n",
        "      best_acc = test_metrics['test acc']\n",
        "      torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
        "    lr_sched.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QSyZus3lD7f"
      },
      "source": [
        "## Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1Wy8hIQfiGqS"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_name=\"lenet\", model_cfg=None, epochs=200):\n",
        "  if model_name == \"lenet\":\n",
        "    model = LeNet()\n",
        "  elif model_name == \"vgg\":\n",
        "    model = VGG(model_cfg)\n",
        "  elif model_name == \"resnet\":\n",
        "    model = ResNet(model_cfg)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "  optim = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
        "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  metric_meter = AvgMeter()\n",
        "  out_dir = f\"{model_name}_{model_cfg}\"\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  train(model, optim, lr_sched, epochs=epochs, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgYPvSM4jUEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88589e27-87d0-4353-d0e5-be69df61a6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.95363 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.71747 [test acc] 0.37950 \n",
            "\u001b[33mtest acc improved from 0 to 0.37950000166893005\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.51619 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.38094 [test acc] 0.48810 \n",
            "\u001b[33mtest acc improved from 0.37950000166893005 to 0.48809999227523804\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.26690 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.22399 [test acc] 0.56700 \n",
            "\u001b[33mtest acc improved from 0.48809999227523804 to 0.5669999718666077\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.03806 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.01758 [test acc] 0.62940 \n",
            "\u001b[33mtest acc improved from 0.5669999718666077 to 0.6294000148773193\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.88917 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.96456 [test acc] 0.67190 \n",
            "\u001b[33mtest acc improved from 0.6294000148773193 to 0.6718999743461609\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.77148 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.76036 [test acc] 0.73490 \n",
            "\u001b[33mtest acc improved from 0.6718999743461609 to 0.7348999977111816\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.68532 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.73776 [test acc] 0.75610 \n",
            "\u001b[33mtest acc improved from 0.7348999977111816 to 0.7560999989509583\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.64084 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72594 [test acc] 0.75230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.59517 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.61743 [test acc] 0.78920 \n",
            "\u001b[33mtest acc improved from 0.7560999989509583 to 0.7892000079154968\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.57168 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.70788 [test acc] 0.76340 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.55194 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.63736 [test acc] 0.78020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.53551 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.70143 [test acc] 0.76790 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.51992 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60166 [test acc] 0.79970 \n",
            "\u001b[33mtest acc improved from 0.7892000079154968 to 0.7997000217437744\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.50926 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58133 [test acc] 0.80590 \n",
            "\u001b[33mtest acc improved from 0.7997000217437744 to 0.805899977684021\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.49607 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.69840 [test acc] 0.77850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.48437 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55158 [test acc] 0.80860 \n",
            "\u001b[33mtest acc improved from 0.805899977684021 to 0.8086000084877014\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.47958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51926 [test acc] 0.82470 \n",
            "\u001b[33mtest acc improved from 0.8086000084877014 to 0.8246999979019165\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.47007 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.72988 [test acc] 0.77040 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.46563 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52629 [test acc] 0.82380 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.68537 [test acc] 0.78000 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.45356 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50645 [test acc] 0.83050 \n",
            "\u001b[33mtest acc improved from 0.8246999979019165 to 0.8305000066757202\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43955 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52323 [test acc] 0.82570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43942 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.66027 [test acc] 0.78090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.43095 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.67259 [test acc] 0.78560 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42667 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.68880 [test acc] 0.77590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42613 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.79409 [test acc] 0.75250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.42129 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58317 [test acc] 0.80790 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41525 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.76923 [test acc] 0.76270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41257 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.62905 [test acc] 0.80030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.41240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50518 [test acc] 0.82470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40441 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.54123 [test acc] 0.81960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40241 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50638 [test acc] 0.82510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58251 [test acc] 0.80910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.40068 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58224 [test acc] 0.80670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50496 [test acc] 0.83240 \n",
            "\u001b[33mtest acc improved from 0.8305000066757202 to 0.8324000239372253\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38802 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.64836 [test acc] 0.79610 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38893 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.48606 [test acc] 0.83700 \n",
            "\u001b[33mtest acc improved from 0.8324000239372253 to 0.8370000123977661\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38061 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.59284 [test acc] 0.80640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38304 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.70145 [test acc] 0.77950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.38449 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.47040 [test acc] 0.84370 \n",
            "\u001b[33mtest acc improved from 0.8370000123977661 to 0.8436999917030334\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36932 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58231 [test acc] 0.81050 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.42776 [test acc] 0.85300 \n",
            "\u001b[33mtest acc improved from 0.8436999917030334 to 0.8529999852180481\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.37026 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.54535 [test acc] 0.81580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36604 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52339 [test acc] 0.83000 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36957 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.60091 [test acc] 0.79670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36649 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46630 [test acc] 0.84720 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.36244 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49361 [test acc] 0.83220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49668 [test acc] 0.83230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35884 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46597 [test acc] 0.84310 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35503 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43333 [test acc] 0.85270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35792 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.52870 [test acc] 0.81690 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34728 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51229 [test acc] 0.83620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.35341 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45851 [test acc] 0.85230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34903 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50394 [test acc] 0.83510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34929 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.55562 [test acc] 0.82090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34222 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51468 [test acc] 0.82890 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33747 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.58498 [test acc] 0.81650 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34021 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41779 [test acc] 0.86060 \n",
            "\u001b[33mtest acc improved from 0.8529999852180481 to 0.8605999946594238\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.34093 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45663 [test acc] 0.85120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33757 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43780 [test acc] 0.85280 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33234 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41584 [test acc] 0.85830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33226 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41894 [test acc] 0.85880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.33081 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50364 [test acc] 0.83620 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32355 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43287 [test acc] 0.85790 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.49308 [test acc] 0.83950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32387 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.47846 [test acc] 0.83850 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31861 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.42683 [test acc] 0.86110 \n",
            "\u001b[33mtest acc improved from 0.8605999946594238 to 0.8611000180244446\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.32487 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.64361 [test acc] 0.79740 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31752 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.81192 [test acc] 0.76200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31635 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50717 [test acc] 0.83590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30763 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41296 [test acc] 0.86620 \n",
            "\u001b[33mtest acc improved from 0.8611000180244446 to 0.8661999702453613\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.31183 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38609 [test acc] 0.86950 \n",
            "\u001b[33mtest acc improved from 0.8661999702453613 to 0.8694999814033508\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30353 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41901 [test acc] 0.86320 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30539 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.44868 [test acc] 0.85240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45827 [test acc] 0.84960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30586 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.36990 [test acc] 0.87470 \n",
            "\u001b[33mtest acc improved from 0.8694999814033508 to 0.8747000098228455\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.29477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38607 [test acc] 0.87170 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.30167 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41395 [test acc] 0.86220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.29155 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39667 [test acc] 0.86330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28952 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.39093 [test acc] 0.87280 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28977 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41007 [test acc] 0.86400 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28519 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.50985 [test acc] 0.83490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.28505 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38076 [test acc] 0.87190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27874 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.41494 [test acc] 0.86720 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27995 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46740 [test acc] 0.85120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27460 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40908 [test acc] 0.86370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.27079 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45431 [test acc] 0.85960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26796 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.46546 [test acc] 0.85390 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26875 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38011 [test acc] 0.87330 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.26870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35506 [test acc] 0.88470 \n",
            "\u001b[33mtest acc improved from 0.8747000098228455 to 0.8847000002861023\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25975 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.44070 [test acc] 0.85780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25905 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40857 [test acc] 0.86780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25878 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.48133 [test acc] 0.84810 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25657 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.77758 [test acc] 0.77050 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24549 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35557 [test acc] 0.88540 \n",
            "\u001b[33mtest acc improved from 0.8847000002861023 to 0.8853999972343445\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.25232 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40673 [test acc] 0.86790 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24093 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.42557 [test acc] 0.86600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.24263 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40200 [test acc] 0.86870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23589 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.45171 [test acc] 0.85290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23984 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32658 [test acc] 0.89140 \n",
            "\u001b[33mtest acc improved from 0.8853999972343445 to 0.8913999795913696\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23593 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35325 [test acc] 0.88430 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.22457 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35541 [test acc] 0.88370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.23154 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.42171 [test acc] 0.86200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.22428 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40660 [test acc] 0.86930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.22559 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33162 [test acc] 0.89270 \n",
            "\u001b[33mtest acc improved from 0.8913999795913696 to 0.8927000164985657\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.21634 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35403 [test acc] 0.88510 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.21398 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33279 [test acc] 0.88910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20914 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.40157 [test acc] 0.86490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.21030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33133 [test acc] 0.88900 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20439 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.36849 [test acc] 0.88230 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20068 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.43404 [test acc] 0.85990 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.20245 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.51372 [test acc] 0.84240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.19609 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32204 [test acc] 0.89730 \n",
            "\u001b[33mtest acc improved from 0.8927000164985657 to 0.8973000049591064\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.19603 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35377 [test acc] 0.87930 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.19041 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34236 [test acc] 0.88880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18828 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33415 [test acc] 0.89110 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18618 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35729 [test acc] 0.88600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18163 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32382 [test acc] 0.89490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.18033 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34159 [test acc] 0.88990 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.17389 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35863 [test acc] 0.88500 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.17318 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.38743 [test acc] 0.87800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.16934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34015 [test acc] 0.89180 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.16517 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31989 [test acc] 0.89780 \n",
            "\u001b[33mtest acc improved from 0.8973000049591064 to 0.8978000283241272\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.15717 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32032 [test acc] 0.89680 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.15854 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33796 [test acc] 0.89290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.15553 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32888 [test acc] 0.89780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.14995 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31549 [test acc] 0.90460 \n",
            "\u001b[33mtest acc improved from 0.8978000283241272 to 0.9046000242233276\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.14528 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.32238 [test acc] 0.89860 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.14062 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.31441 [test acc] 0.90100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13932 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27933 [test acc] 0.91080 \n",
            "\u001b[33mtest acc improved from 0.9046000242233276 to 0.9107999801635742\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13691 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.35602 [test acc] 0.88950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13320 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.33779 [test acc] 0.90070 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.13229 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.34144 [test acc] 0.89360 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.12333 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27928 [test acc] 0.91230 \n",
            "\u001b[33mtest acc improved from 0.9107999801635742 to 0.9122999906539917\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.12087 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29792 [test acc] 0.90900 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.11483 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30759 [test acc] 0.90630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.12130 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.30335 [test acc] 0.90880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10780 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27510 [test acc] 0.91500 \n",
            "\u001b[33mtest acc improved from 0.9122999906539917 to 0.9150000214576721\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10649 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28454 [test acc] 0.91220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.10341 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29504 [test acc] 0.90940 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.09724 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29406 [test acc] 0.90960 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.09890 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28721 [test acc] 0.91090 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.09540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29660 [test acc] 0.91310 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08866 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29428 [test acc] 0.91320 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08766 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27214 [test acc] 0.91780 \n",
            "\u001b[33mtest acc improved from 0.9150000214576721 to 0.9178000092506409\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08372 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28678 [test acc] 0.91420 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.08064 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26623 [test acc] 0.92070 \n",
            "\u001b[33mtest acc improved from 0.9178000092506409 to 0.9207000136375427\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.07383 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.29069 [test acc] 0.91580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.06877 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26066 [test acc] 0.92450 \n",
            "\u001b[33mtest acc improved from 0.9207000136375427 to 0.9244999885559082\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.06892 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27363 [test acc] 0.91760 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.06816 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27081 [test acc] 0.92280 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05737 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26413 [test acc] 0.92150 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05935 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.24710 [test acc] 0.92780 \n",
            "\u001b[33mtest acc improved from 0.9244999885559082 to 0.9277999997138977\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05287 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26031 [test acc] 0.92820 \n",
            "\u001b[33mtest acc improved from 0.9277999997138977 to 0.9282000064849854\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.05026 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.24825 [test acc] 0.92840 \n",
            "\u001b[33mtest acc improved from 0.9282000064849854 to 0.9283999800682068\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.04515 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26445 [test acc] 0.92530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.04193 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.28094 [test acc] 0.92250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.04193 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26351 [test acc] 0.92830 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03825 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.27104 [test acc] 0.92480 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03232 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26350 [test acc] 0.92650 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.03303 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.24541 [test acc] 0.93400 \n",
            "\u001b[33mtest acc improved from 0.9283999800682068 to 0.9340000152587891\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02949 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26183 [test acc] 0.92880 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02296 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.25549 [test acc] 0.92990 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02649 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.23881 [test acc] 0.93340 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02083 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.26057 [test acc] 0.93100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.02140 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.21731 [test acc] 0.94050 \n",
            "\u001b[33mtest acc improved from 0.9340000152587891 to 0.940500020980835\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01571 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.21873 [test acc] 0.94100 \n",
            "\u001b[33mtest acc improved from 0.940500020980835 to 0.9409999847412109\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01429 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.22339 [test acc] 0.94120 \n",
            "\u001b[33mtest acc improved from 0.9409999847412109 to 0.9412000179290771\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01302 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.22566 [test acc] 0.94210 \n",
            "\u001b[33mtest acc improved from 0.9412000179290771 to 0.9420999884605408\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00988 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.22739 [test acc] 0.94320 \n",
            "\u001b[33mtest acc improved from 0.9420999884605408 to 0.9431999921798706\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.01055 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.21139 [test acc] 0.94530 \n",
            "\u001b[33mtest acc improved from 0.9431999921798706 to 0.9452999830245972\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00716 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.20499 [test acc] 0.94780 \n",
            "\u001b[33mtest acc improved from 0.9452999830245972 to 0.9477999806404114\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00597 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.20523 [test acc] 0.94670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00530 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.20023 [test acc] 0.94590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00407 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.19348 [test acc] 0.95010 \n",
            "\u001b[33mtest acc improved from 0.9477999806404114 to 0.9501000046730042\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00338 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.19499 [test acc] 0.94840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00342 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.19026 [test acc] 0.95010 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00314 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.19102 [test acc] 0.94860 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00269 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18627 [test acc] 0.94950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00259 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18282 [test acc] 0.95250 \n",
            "\u001b[33mtest acc improved from 0.9501000046730042 to 0.9524999856948853\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00279 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18155 [test acc] 0.95240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00238 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18071 [test acc] 0.95180 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00223 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18173 [test acc] 0.95190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00220 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18210 [test acc] 0.95110 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00213 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18233 [test acc] 0.95210 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00201 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18102 [test acc] 0.95190 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00198 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.18011 [test acc] 0.95250 \n",
            "\u001b[33mtest acc improved from 0.9524999856948853 to 0.9524999856948853\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00189 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17990 [test acc] 0.95240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00193 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17863 [test acc] 0.95270 \n",
            "\u001b[33mtest acc improved from 0.9524999856948853 to 0.9527000188827515\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00194 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17838 [test acc] 0.95260 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00206 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17853 [test acc] 0.95260 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00199 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17688 [test acc] 0.95260 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00195 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17726 [test acc] 0.95310 \n",
            "\u001b[33mtest acc improved from 0.9527000188827515 to 0.9531000256538391\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00186 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17681 [test acc] 0.95340 \n",
            "\u001b[33mtest acc improved from 0.9531000256538391 to 0.9534000158309937\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00175 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17743 [test acc] 0.95390 \n",
            "\u001b[33mtest acc improved from 0.9534000158309937 to 0.9538999795913696\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00196 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17645 [test acc] 0.95300 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 0.00179 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 0.17726 [test acc] 0.95290 \n"
          ]
        }
      ],
      "source": [
        "#run_experiment(model_name=\"lenet\")\n",
        "#run_experiment(model_name=\"vgg\",model_cfg=\"vgg16\")\n",
        "run_experiment(model_name=\"resnet\",model_cfg=\"resnet18\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3afd43ab438647739cac7cb7fb0af123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48feeba233b141c5898c9ff7f088ec0a",
              "IPY_MODEL_720ff9f4c25045c59627e505028c9184",
              "IPY_MODEL_833bdbf80ab3407abf01045099ff4000"
            ],
            "layout": "IPY_MODEL_1b4d4ea3e3c548988f47cd0ae8aadc6f"
          }
        },
        "48feeba233b141c5898c9ff7f088ec0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad00e33feaec427f8962d5e2f5a8fde8",
            "placeholder": "",
            "style": "IPY_MODEL_f423142f0ab342b3a20c2fa7e7b73b41",
            "value": "100%"
          }
        },
        "720ff9f4c25045c59627e505028c9184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f5604493e04528babe637b63274acf",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1de76a75f9646f79099b00681b8577a",
            "value": 170498071
          }
        },
        "833bdbf80ab3407abf01045099ff4000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2edc56c583504cfc9416692e821bf2d4",
            "placeholder": "",
            "style": "IPY_MODEL_8e27e56fcc214224beb88235128c3570",
            "value": " 170498071/170498071 [00:13&lt;00:00, 13632773.97it/s]"
          }
        },
        "1b4d4ea3e3c548988f47cd0ae8aadc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad00e33feaec427f8962d5e2f5a8fde8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f423142f0ab342b3a20c2fa7e7b73b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f5604493e04528babe637b63274acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1de76a75f9646f79099b00681b8577a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2edc56c583504cfc9416692e821bf2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e27e56fcc214224beb88235128c3570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}